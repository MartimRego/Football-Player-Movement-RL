{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26dd4417-0723-4608-bbf5-df2c807ce853",
   "metadata": {},
   "source": [
    "# xG model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabdfb58-39b0-4cff-89ce-9f5fc9de68e0",
   "metadata": {},
   "source": [
    "##### This code is borrowed heavily from https://github.com/Friends-of-Tracking-Data-FoTD/SoccermaticsForPython for the data treatment section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a701483-a332-48a5-abbe-081946ebbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import FCPython \n",
    "\n",
    "#Statistical fitting of models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c90f8a-67c3-4ed3-a049-63f74828c5be",
   "metadata": {},
   "source": [
    "##### Single run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65dcc09-b197-42fa-a48b-8901f373448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Decide which league to load\n",
    "#Wyscout data from https://figshare.com/collections/Soccer_match_event_dataset/4415000/2\n",
    "with open('All_data.json') as f: #All_data is a dataset consisting of the fusion of all 7 competitions\n",
    "    data = json.load(f)\n",
    "\n",
    "train = pd.DataFrame(data)\n",
    "\n",
    "shots=train[train['subEventName']=='Shot']\n",
    "\n",
    "shots_model=pd.DataFrame(columns=['Goal','X','Y'])\n",
    "\n",
    "#Go through the dataframe and calculate X, Y co-ordinates.\n",
    "#Distance from a line in the centre\n",
    "#Shot angle.\n",
    "#Details of tags can be found here: https://apidocs.wyscout.com/matches-wyid-events\n",
    "for i,shot in shots.iterrows():\n",
    "    \n",
    "    header=0\n",
    "    for shottags in shot['tags']:\n",
    "        if shottags['id']==403:\n",
    "            header=1\n",
    "    #Only include non-headers        \n",
    "    if not(header):        \n",
    "        shots_model.at[i,'X']=100-shot['positions'][0]['x']\n",
    "        shots_model.at[i,'Y']=shot['positions'][0]['y']\n",
    "        shots_model.at[i,'C']=abs(shot['positions'][0]['y']-50)\n",
    "    \n",
    "        #Distance in metres and shot angle in radians.\n",
    "        x=shots_model.at[i,'X']*105/100\n",
    "        y=shots_model.at[i,'C']*65/100\n",
    "        shots_model.at[i,'Distance']=np.sqrt(x**2 + y**2)\n",
    "        a = np.arctan(7.32 *x /(x**2 + y**2 - (7.32/2)**2))\n",
    "        if a<0:\n",
    "            a=np.pi+a\n",
    "        shots_model.at[i,'Angle'] =a\n",
    "    \n",
    "        #Was it a goal\n",
    "        shots_model.at[i,'Goal']=0\n",
    "        for shottags in shot['tags']:\n",
    "                #Tags contain that its a goal\n",
    "                if shottags['id']==101:\n",
    "                    shots_model.at[i,'Goal']=1\n",
    "\n",
    "\n",
    "shots_model.to_csv('shots.csv', index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0910c2d9-d119-4576-a6cb-c4d59aec4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('shots.csv') #Load dataset with all shots from the 7 competitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f2c7c-fa22-4690-8af2-60c40f518398",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a19984-192b-4f80-b25d-b742b0117d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(['Goal','X','Y','C'], axis=1)\n",
    "y = data['Goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ec601-f9d4-4c48-8c66-b0f6fdaa55b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x= 'Distance', \n",
    "           y= 'Angle', \n",
    "           height=15,\n",
    "           aspect=1,\n",
    "           data=data, \n",
    "           fit_reg=False, \n",
    "           hue= 'Goal', \n",
    "           legend=True)\n",
    "\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Angle\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd3053-d8f0-44a9-b575-b57e7c5b9227",
   "metadata": {},
   "source": [
    "##### Data standardization (not used as it yielded worst results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c90092-a1f2-4cbf-a2c9-ad1bc7d25ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5559ed5-2a34-4cf5-bae9-4164d0ecb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "xtrain, xtest, ytrain, ytest = train_test_split( \n",
    "    x, y, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76f2c1-aa5d-4529-bc68-0329d333262d",
   "metadata": {},
   "source": [
    "#### We implement oversampling and undersampling techniques (SMOTE, ADASYN and Cluster Centroids) until we have full class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b04515-ab6d-426c-8b43-1ae2fcac665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state = 123)\n",
    "xtrain_smote, ytrain_smote = oversample.fit_resample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61687b-283c-434e-bb6c-639d0971f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = ADASYN(sampling_strategy = 0.5, random_state = 123)\n",
    "xtrain_ada, ytrain_ada = oversample.fit_resample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad9465-5cf7-40f4-a0b0-f54622bd3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(random_state = 123)\n",
    "xtrain_res, ytrain_res = cc.fit_resample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d4a86-0eb8-4433-ae95-736aa1e816f3",
   "metadata": {},
   "source": [
    "### Logistic Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be5b7e-16f7-4ab7-8f63-077ac30c5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "classifier = LogisticRegression(random_state = 123) \n",
    "classifier.fit(xtrain, ytrain)\n",
    "y_pred = classifier.predict(xtest)\n",
    "y_score = classifier.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print('Coefficients:' ,classifier.coef_)\n",
    "print('Intercept:' ,classifier.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1275cdb-4040-4bc2-915b-172c536e59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 123) \n",
    "classifier.fit(xtrain_smote, ytrain_smote)\n",
    "y_pred = classifier.predict(xtest)\n",
    "y_score = classifier.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print('Coefficients:' ,classifier.coef_)\n",
    "print('Intercept:' ,classifier.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbb5b2-8325-4edc-8c41-4307e541bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 123) \n",
    "classifier.fit(xtrain_ada, ytrain_ada)\n",
    "y_pred = classifier.predict(xtest)\n",
    "y_score = classifier.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print('Coefficients:' ,classifier.coef_)\n",
    "print('Intercept:' ,classifier.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e65fb-5543-48e8-88d3-23a1d31a1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 123) \n",
    "classifier.fit(xtrain_res, ytrain_res)\n",
    "y_pred = classifier.predict(xtest)\n",
    "y_score = classifier.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print('Coefficients:' ,classifier.coef_)\n",
    "print('Intercept:' ,classifier.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7778bd55-e19f-4991-9ba6-2a0a57b03eb9",
   "metadata": {},
   "source": [
    "### XGBOOST models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c6699-a830-4f98-ba1c-38bed1d80360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262565f-17c1-40e8-bcbb-2340915eb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the XGBClassifier\n",
    "model = XGBClassifier(objective='binary:logistic', base_score = 0.1) #Base score of 0.1 accounts for class imbalance\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(xtrain, ytrain)\n",
    "y_pred = model.predict(xtest)\n",
    "y_score = model.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f481b4-1d42-49a7-8f5b-3be364263330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the XGBClassifier\n",
    "model = XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(xtrain_smote, ytrain_smote)\n",
    "y_pred = model.predict(xtest)\n",
    "y_score = model.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875e2c6-14b3-4006-804e-05c452a6247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the XGBClassifier\n",
    "model = XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(xtrain_ada, ytrain_ada)\n",
    "y_pred = model.predict(xtest)\n",
    "y_score = model.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f8259-b949-45ce-a338-07461458cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the XGBClassifier\n",
    "model = XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(xtrain_res, ytrain_res)\n",
    "y_pred = model.predict(xtest)\n",
    "y_score = model.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9240e32-9c01-4351-b2a4-bf3ad3cd3279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
