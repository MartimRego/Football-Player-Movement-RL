{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0724735-2178-4857-90d4-05b5df637eca",
   "metadata": {},
   "source": [
    "# Implementation of the Pressure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40baeb05-c27e-4fa0-9fb6-018919443815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "\n",
    "#Statistical fitting of models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#Sklearn metrics\n",
    "from sklearn.metrics import roc_curve, f1_score, roc_auc_score, precision_recall_curve, auc, accuracy_score,confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Imbalanced learning package for synthetic data\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "#Model Packages\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9070587-aefa-43e1-b995-621ce34c1927",
   "metadata": {},
   "source": [
    "#### Choose dataset to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520e715-a26c-4b9a-8b1a-b34a029694d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"FixedRBF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc58dd-adef-4d90-b370-48a648d85c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc4b65-2a89-4027-97a1-259dfa9a96fa",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e61efc-8d54-4286-a158-939b6b6059ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301fcdd6-c674-4277-bcc9-a88b0c8aac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d44f1-35b4-4703-8479-7a5e0f0d5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(['SuccessFlag','Frame'], axis=1)\n",
    "y = data['SuccessFlag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefaf1f2-963b-4926-8938-a273b22fd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x= 'DistanceGoal', \n",
    "           y= 'MinDistance', \n",
    "           data=data, \n",
    "           hue= 'SuccessFlag',\n",
    "           size = 'FreePlayers'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"DistanceGoal\")\n",
    "plt.ylabel(\"MinDistance\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bf405c-4d7c-4e16-ad95-929a0ad1cccb",
   "metadata": {},
   "source": [
    "##### Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b8c6d-aade-41af-8d0c-0825cb18ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5447345-e7e4-452d-b54f-8370222b544a",
   "metadata": {},
   "source": [
    "##### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade74352-7888-47e0-9ef2-0a9e52134154",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split( \n",
    "    x, y, test_size=0.25, random_state=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2de39a-068d-46ca-b654-3e9e39f7ca20",
   "metadata": {},
   "source": [
    "##### Implementation of oversampling and undersampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a4dab-a8b4-4459-977a-2bcdebd47421",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state = 2023)\n",
    "xtrain_smote, ytrain_smote = oversample.fit_resample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fead495-7aee-4532-ba5a-9894d3df82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = ADASYN(random_state = 2023)\n",
    "xtrain_ada, ytrain_ada = oversample.fit_resample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365b824-bb14-4ade-832e-691dc006e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(random_state = 2023)\n",
    "xtrain_res, ytrain_res = cc.fit_resample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d6179-3a87-4979-8e2e-7cda83dcefff",
   "metadata": {},
   "source": [
    "### Perform a best subset search for logistic regression in terms of AUC score (Always outputs entire set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672b675-d050-4454-ad58-7420a8b82b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_regression(features, target):\n",
    "    features = sm.add_constant(features)\n",
    "    model = sm.Logit(target, features)\n",
    "    result = model.fit(disp=0)\n",
    "    return result\n",
    "\n",
    "def get_best_model(features, target, candidate_predictors):\n",
    "    best_model = None\n",
    "    best_auc = 0.0\n",
    "\n",
    "    for subset in itertools.combinations(candidate_predictors, len(candidate_predictors)):\n",
    "        current_features = features[:, list(subset)]\n",
    "        result = fit_logistic_regression(current_features, target)\n",
    "        y_pred_prob = result.predict(sm.add_constant(current_features))\n",
    "        current_auc = roc_auc_score(target, y_pred_prob)\n",
    "\n",
    "        if current_auc > best_auc:\n",
    "            best_auc = current_auc\n",
    "            best_model = result\n",
    "            best_subset = subset\n",
    "\n",
    "    return best_model, best_subset\n",
    "\n",
    "# Create a list of predictor indices\n",
    "num_predictors = xtrain.shape[1]\n",
    "predictor_indices = list(range(num_predictors))\n",
    "\n",
    "# Get the best model and subset based on AUC\n",
    "best_model, best_subset = get_best_model(xtrain, ytrain, predictor_indices)\n",
    "\n",
    "# Print the best subset and model summary\n",
    "print(\"Best Subset:\", best_subset)\n",
    "print(best_model.summary(xname = ['Intercept']+list(data.drop(['SuccessFlag','Frame'],axis = 1).columns))) #To have the variable names, we use the fact that all variables are used\n",
    "\n",
    "# Make predictions on the test set using the best subset\n",
    "xtest_subset = xtest[:, list(best_subset)]\n",
    "ypred_prob = best_model.predict(sm.add_constant(xtest_subset))\n",
    "\n",
    "# Evaluate the AUC of the model on the test set\n",
    "test_auc = roc_auc_score(ytest, ypred_prob)\n",
    "print(\"Test AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7635873e-4f8a-4ad6-96d8-08b4dba7db30",
   "metadata": {},
   "source": [
    "### Logistic regression fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcdf84c-69fc-4979-8b63-2eccaccab0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 2023) \n",
    "classifier.fit(xtrain, ytrain)\n",
    "y_pred = classifier.predict(xtest)\n",
    "y_score = classifier.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print('Coefficients:' ,classifier.coef_)\n",
    "print('Intercept:' ,classifier.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063a498-4d4a-4ca3-b874-534453722d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 2023) \n",
    "classifier.fit(xtrain_smote, ytrain_smote)\n",
    "y_pred = classifier.predict(xtest)\n",
    "y_score = classifier.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print('Coefficients:' ,classifier.coef_)\n",
    "print('Intercept:' ,classifier.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745b5a0-036e-4307-9557-709c49d024ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 2023) \n",
    "classifier.fit(xtrain_ada, ytrain_ada)\n",
    "y_pred = classifier.predict(xtest)\n",
    "y_score = classifier.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print('Coefficients:' ,classifier.coef_)\n",
    "print('Intercept:' ,classifier.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54e3b2-6419-4e73-af2d-d6248ebd6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 2023) \n",
    "classifier.fit(xtrain_res, ytrain_res)\n",
    "y_pred = classifier.predict(xtest)\n",
    "y_score = classifier.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print('Coefficients:' ,classifier.coef_)\n",
    "print('Intercept:' ,classifier.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602bfa6-ed93-4d54-b37c-9ec8627ff8ef",
   "metadata": {},
   "source": [
    "### Perform bayesian optimization over the xgboost hyperparameters with AUC as the scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df912bf0-9400-4154-a31e-193a583ac10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('clf', XGBClassifier(random_state=123, device = 'cuda',tree_method = 'hist')) # can customize objective function with the objective parameter\n",
    "]\n",
    "pipe = Pipeline(steps=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ff080-6b83-4df4-afd0-710dfe2b0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'clf__max_depth': Integer(2,8),\n",
    "    'clf__learning_rate': Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample': Real(0.5, 1.0),\n",
    "    'clf__colsample_bytree': Real(0.5, 1.0),\n",
    "    'clf__colsample_bylevel': Real(0.5, 1.0),\n",
    "    'clf__colsample_bynode' : Real(0.5, 1.0),\n",
    "    'clf__reg_alpha': Real(0.0, 10.0),\n",
    "    'clf__reg_lambda': Real(0.0, 10.0),\n",
    "    'clf__gamma': Real(0.0, 10.0),\n",
    "    'clf__n_estimators': Integer(100,1000),\n",
    "    'clf__n_jobs': Integer(11.5,12.5), #Admiteddly lazy way to get 12 processors working, adjust if needed\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(pipe, search_space, cv=10, n_iter=100, scoring='roc_auc', random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f21ab6-e6ac-4920-b217-4c51709708ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bccab7-fb44-4874-89b2-59c688f1aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21471101-ef44-46c1-82b4-a8419d976a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870b6fc-3824-4d5f-a8bb-4009aa6e6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19245486-253b-4dba-9a9b-dc105c621119",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68acf8d3-4521-4c9e-bde9-7c64b41dc3a8",
   "metadata": {},
   "source": [
    "## Models obtained:\n",
    "\n",
    "For RBF:\n",
    "\n",
    "model = XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=0.5, colsample_bynode=1.0, colsample_bytree=0.5,\n",
    "                device='cuda', early_stopping_rounds=None,\n",
    "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "                gamma=0.3404126229044155, grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.003911225659823791,\n",
    "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=8, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                multi_strategy=None, n_estimators=1000, n_jobs=12,\n",
    "                num_parallel_tree=None, random_state=123)\n",
    "\n",
    "For KNN:\n",
    "\n",
    "model = XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=0.8445304034569212, colsample_bynode=1.0,\n",
    "                colsample_bytree=0.5, device='cuda', early_stopping_rounds=None,\n",
    "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "                gamma=4.733212503552665, grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.48945402372274754,\n",
    "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=2, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                multi_strategy=None, n_estimators=1000, n_jobs=12,\n",
    "                num_parallel_tree=None, random_state=123)\n",
    "\n",
    "For hierarchical:\n",
    "\n",
    "model = XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "                colsample_bylevel=0.5, colsample_bynode=1.0, colsample_bytree=1.0,\n",
    "                device='cuda', early_stopping_rounds=None,\n",
    "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "                gamma=3.9022057058351827, grow_policy=None, importance_type=None,\n",
    "                interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
    "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "                max_delta_step=None, max_depth=8, max_leaves=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                multi_strategy=None, n_estimators=1000, n_jobs=12,\n",
    "                num_parallel_tree=None, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285a058-16cc-41ef-ad08-801262b71ad5",
   "metadata": {},
   "source": [
    "### XGBOOST fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad39247-4cb6-4528-b1e7-a08715b9963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(base_score=None, booster=None, callbacks=None, colsample_bylevel=0.5, colsample_bynode=1.0, colsample_bytree=0.5, device='cuda', early_stopping_rounds=None, enable_categorical=False, eval_metric=None, feature_types=None, gamma=0.3404126229044155, grow_policy=None, importance_type=None, interaction_constraints=None, learning_rate=0.003911225659823791, max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=None, max_depth=8, max_leaves=None, min_child_weight=None, monotone_constraints=None, multi_strategy=None, n_estimators=1000, n_jobs=12, num_parallel_tree=None, random_state=123)\n",
    "model.fit(xtrain, ytrain)\n",
    "y_pred = model.predict(xtest)\n",
    "y_score = model.predict_proba(xtest)[:, 1]\n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
    "print(\"F1Score : \",f1_score(ytest, y_pred, average=\"weighted\"))\n",
    "print(\"AUC Score : \", roc_auc_score(ytest, y_score))\n",
    "precision, recall, _= precision_recall_curve(ytest, y_score) \n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC Score:\", pr_auc)\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_score)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f' % (best_thresh))\n",
    "threshold = best_thresh\n",
    "y_pred = (y_score >= best_thresh).astype(int)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print('Accuracy with custom threshold:' , accuracy_score(ytest, y_pred))\n",
    "print('F1Score with custom threshold:' , f1_score(ytest, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b622635-2638-4055-a6d5-ed64889c8e32",
   "metadata": {},
   "source": [
    "## Analysis on feature influence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f725e31a-5a38-44a8-90fe-210b8e7ef227",
   "metadata": {},
   "source": [
    "#### Feature importance (gini index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d939da-fa74-43c0-99a7-99a2ca0ed79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(data.drop(['SuccessFlag','Frame'], axis=1).columns)[sorted_idx])\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447124f8-7a4d-4b1e-9a32-b3f7285a94a5",
   "metadata": {},
   "source": [
    "#### SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719be2a-0b63-4a8b-b040-f1b3963d2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "explainer = shap.Explainer(model,feature_names = list(data.drop(['SuccessFlag','Frame'], axis=1).columns))\n",
    "shap_values = explainer(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e82a6b-279b-4aa0-a404-ec1e70a13bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d637db5-be19-493d-ba23-9adc7aa27ae1",
   "metadata": {},
   "source": [
    "#### PDP plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae4dad-ca61-4975-9f0a-e7d02a30e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "classifier = LogisticRegression(random_state = 2023) \n",
    "classifier.fit(xtrain, ytrain)\n",
    "# Computing partial dependence plots\n",
    "#features = list(range(14))\n",
    "features = [11]\n",
    "PartialDependenceDisplay.from_estimator(model, xtest, features, feature_names=list(data.drop(['SuccessFlag','Frame'], axis=1).columns),\n",
    "                        n_jobs=3, grid_resolution=80)\n",
    "#disp1 = PartialDependenceDisplay.from_estimator(model, xtest, features, feature_names=list(data.drop(['SuccessFlag','Frame'], axis=1).columns),\n",
    "#                        n_jobs=3, grid_resolution=80, line_kw={\"label\": \"XGBOOST\"})\n",
    "#disp2 = PartialDependenceDisplay.from_estimator(classifier, xtest, features, feature_names=list(data.drop(['SuccessFlag','Frame'], axis=1).columns),\n",
    "#                        n_jobs=3, grid_resolution=80, ax = disp1.axes_, line_kw={\"label\": \"Logistic Regression\",\"color\": \"red\"})\n",
    "fig = plt.gcf()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(10)\n",
    "fig.subplots_adjust(wspace=1, hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f0192-9f8d-4b93-b0c4-634c2a471a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
